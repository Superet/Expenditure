m	<- with(param_list, (tau1-beta*log(K)+(1-beta)*lambda1) / (2*tau2-2*lambda2*(1-beta) ))	#
	n	<- with(param_list, 2*tau2/(2*tau2 - 2*lambda2*(1-beta)) )
c(m=m,n=n)
state <- c(4,6)
Dynamic discrete choice model solution #
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .8,#
					sigma_y = .5)#
K <- 3#
mu_Q <- c(1, 1, 2)#
sigma_Q <- c(.03, .05, .1)					#
#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)
state <- c(4,6)
str(DP_list)
n.nodes <- nrow(GH_init$nodes)#
	m		<- DP_list$consumption[m]#
	n		<- DP_list$consumption[n]#
	x_prim	<- array(NA,c(K,n.nodes,state_dim))#
	flow_u	<- rep(NA,K)#
	v		<- rep(NA,K)
m		<- DP_list$consumption["m"]#
	n		<- DP_list$consumption["n"]
k <- 1
sigma 	<- sigma_Q[k]#
		a0 		<- -(m/n + mu_Q[k])/sigma#
		b0 		<- -(m/(n-1) + mu_Q[k])/sigma#
		mu 		<- state[I.idx] + mu_Q[k]
a0
b0
if(pnorm(a0)<Phi.bound){#
			EQ_lower	<- 0 #
			EQ2_lower	<- 0#
		}else{#
			rho 		<- dnorm(a0)/pnorm(a0)#
			EQ_lower	<- mu - sigma*rho#
			EQ2_lower	<- mu^2 - 2*mu*sigma*rho + sigma^2*(1+a0*rho)#
		}#
#
		if(pnorm(-b0)<Phi.bound){#
			EQ_upper	<- 0#
			EQ2_upper	<- 0#
		}else{#
			rho 		<- dnorm(b0)/pnorm(-b0)#
			EQ_upper	<- mu + sigma*rho#
			EQ2_upper	<- mu^2 + 2*mu*sigma*rho +sigma^2*(1+b0*rho)#
		}#
#
		p.mid <- pnorm(b0) - pnorm(a0)#
		if(p.mid<Phi.bound){#
			EQ_mid		<- 0 #
			EQ2_mid		<- 0#
			Ec_mid		<- 0#
			Ec2_mid		<- 0#
			EI_mid		<- 0#
			EI2_mid		<- 0 #
		}else{#
			EQ_mid		<- mu - sigma*(dnorm(b0)-dnorm(a0))/p.mid#
			EQ2_mid		<- mu^2 - 2*mu*sigma*(dnorm(b0) - dnorm(a0))/p.mid + sigma^2*(1 - (b0*dnorm(b0) - a0*dnorm(a0))/p.mid)#
			Ec_mid		<- m*p.mid + n*EQ_mid#
			Ec2_mid		<- m^2*p.mid + 2*m*n*EQ_mid + n^2*EQ2_mid#
			EI_mid		<- -m*p.mid - (n-1)*EQ_mid#
			EI2_mid		<- m^2*p.mid + 2*m*(n-1)*EQ_mid + (n-1)^2*EQ2_mid#
		}
Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)
if(pnorm(a0)<set_list$Phi.bound){#
			EQ_lower	<- 0 #
			EQ2_lower	<- 0#
		}else{#
			rho 		<- dnorm(a0)/pnorm(a0)#
			EQ_lower	<- mu - sigma*rho#
			EQ2_lower	<- mu^2 - 2*mu*sigma*rho + sigma^2*(1+a0*rho)#
		}#
#
		if(pnorm(-b0)<set_list$Phi.bound){#
			EQ_upper	<- 0#
			EQ2_upper	<- 0#
		}else{#
			rho 		<- dnorm(b0)/pnorm(-b0)#
			EQ_upper	<- mu + sigma*rho#
			EQ2_upper	<- mu^2 + 2*mu*sigma*rho +sigma^2*(1+b0*rho)#
		}#
#
		p.mid <- pnorm(b0) - pnorm(a0)#
		if(p.mid<set_list$Phi.bound){#
			EQ_mid		<- 0 #
			EQ2_mid		<- 0#
			Ec_mid		<- 0#
			Ec2_mid		<- 0#
			EI_mid		<- 0#
			EI2_mid		<- 0 #
		}else{#
			EQ_mid		<- mu - sigma*(dnorm(b0)-dnorm(a0))/p.mid#
			EQ2_mid		<- mu^2 - 2*mu*sigma*(dnorm(b0) - dnorm(a0))/p.mid + sigma^2*(1 - (b0*dnorm(b0) - a0*dnorm(a0))/p.mid)#
			Ec_mid		<- m*p.mid + n*EQ_mid#
			Ec2_mid		<- m^2*p.mid + 2*m*n*EQ_mid + n^2*EQ2_mid#
			EI_mid		<- -m*p.mid - (n-1)*EQ_mid#
			EI2_mid		<- m^2*p.mid + 2*m*(n-1)*EQ_mid + (n-1)^2*EQ2_mid#
		}
Expected consumption, inventory and flow utility#
		Ec 			<- EQ_upper + Ec_mid#
		Ec2			<- EQ2_upper + Ec2_mid#
		EI_prim		<- EQ_lower + EI_mid#
		EI2_prim	<- EQ2_lower + EI2_mid#
		flow_u[k]	<- with(param_list, lambda1*Ec + lambda2*Ec2 - tau1*EI_prim - tau2*EI2_prim)
The nodes at which to compute integral of value function#
		I_prim		<- cbind(-m-(n-1)*(mu + sqrt(2)*sigma*GH_init$nodes[,I.idx]), #
							 mu + sqrt(2)*sigma*GH_init$nodes[,I.idx]	)#
		I_prim		<- apply(I_prim,1,function(x) min(max(x[1],0),x[2]) )#
		y_prim		<- state[y.idx] + sqrt(2)*param_list$sigma_y * GH_init$nodes[,y.idx]#
		x_prim[k,,I.idx] <- sapply(I_prim, function(x) min(max(x,cheby_init$lower[I.idx]),cheby_init$upper[I.idx]) )#
		x_prim[k,,y.idx] <- sapply(y_prim, function(x) min(max(x,cheby_init$lower[y.idx]),cheby_init$upper[y.idx]) )
x_prim[k,,]
Re-normalize nodes to compute Chebychev approximation of expected value funtion#
		x_prim_adj		<- 2*(x_prim[k,,] - rep(1,n.nodes)%*%t(cheby_init$lower))/#
							(rep(1,n.nodes) %*% t(cheby_init$upper - cheby_init$lower)) - 1#
		T 				<- apply(x_prim_adj,1,cheb_polynm_multD,cheby_init$Polynomial.degree)#
		ET				<- apply(T,1,function(x) x %*% GH_init$weights)/pi#
		Ew				<- ET %*% DP_list$Cheb.theta
x_prim_adj
T
ET
Ew
n.nodes <- nrow(GH_init$nodes)#
	m		<- DP_list$consumption["m"]#
	n		<- DP_list$consumption["n"]#
	x_prim	<- array(NA,c(K,n.nodes,state_dim))#
	flow_u	<- rep(NA,K)#
	v		<- rep(NA,K)#
	for(k in 1:K){#
		sigma 	<- sigma_Q[k]#
		a0 		<- -(m/n + mu_Q[k])/sigma#
		b0 		<- -(m/(n-1) + mu_Q[k])/sigma#
		mu 		<- state[I.idx] + mu_Q[k]#
		if(pnorm(a0)<set_list$Phi.bound){#
			EQ_lower	<- 0 #
			EQ2_lower	<- 0#
		}else{#
			rho 		<- dnorm(a0)/pnorm(a0)#
			EQ_lower	<- mu - sigma*rho#
			EQ2_lower	<- mu^2 - 2*mu*sigma*rho + sigma^2*(1+a0*rho)#
		}#
#
		if(pnorm(-b0)<set_list$Phi.bound){#
			EQ_upper	<- 0#
			EQ2_upper	<- 0#
		}else{#
			rho 		<- dnorm(b0)/pnorm(-b0)#
			EQ_upper	<- mu + sigma*rho#
			EQ2_upper	<- mu^2 + 2*mu*sigma*rho +sigma^2*(1+b0*rho)#
		}#
#
		p.mid <- pnorm(b0) - pnorm(a0)#
		if(p.mid<set_list$Phi.bound){#
			EQ_mid		<- 0 #
			EQ2_mid		<- 0#
			Ec_mid		<- 0#
			Ec2_mid		<- 0#
			EI_mid		<- 0#
			EI2_mid		<- 0 #
		}else{#
			EQ_mid		<- mu - sigma*(dnorm(b0)-dnorm(a0))/p.mid#
			EQ2_mid		<- mu^2 - 2*mu*sigma*(dnorm(b0) - dnorm(a0))/p.mid + sigma^2*(1 - (b0*dnorm(b0) - a0*dnorm(a0))/p.mid)#
			Ec_mid		<- m*p.mid + n*EQ_mid#
			Ec2_mid		<- m^2*p.mid + 2*m*n*EQ_mid + n^2*EQ2_mid#
			EI_mid		<- -m*p.mid - (n-1)*EQ_mid#
			EI2_mid		<- m^2*p.mid + 2*m*(n-1)*EQ_mid + (n-1)^2*EQ2_mid#
		}#
#
		# Expected consumption, inventory and flow utility#
		Ec 			<- EQ_upper + Ec_mid#
		Ec2			<- EQ2_upper + Ec2_mid#
		EI_prim		<- EQ_lower + EI_mid#
		EI2_prim	<- EQ2_lower + EI2_mid#
		flow_u[k]	<- with(param_list, lambda1*Ec + lambda2*Ec2 - tau1*EI_prim - tau2*EI2_prim)#
		# The nodes at which to compute integral of value function#
		I_prim		<- cbind(-m-(n-1)*(mu + sqrt(2)*sigma*GH_init$nodes[,I.idx]), #
							 mu + sqrt(2)*sigma*GH_init$nodes[,I.idx]	)#
		I_prim		<- apply(I_prim,1,function(x) min(max(x[1],0),x[2]) )#
		y_prim		<- state[y.idx] + sqrt(2)*param_list$sigma_y * GH_init$nodes[,y.idx]#
		x_prim[k,,I.idx] <- sapply(I_prim, function(x) min(max(x,cheby_init$lower[I.idx]),cheby_init$upper[I.idx]) )#
		x_prim[k,,y.idx] <- sapply(y_prim, function(x) min(max(x,cheby_init$lower[y.idx]),cheby_init$upper[y.idx]) )#
		# Re-normalize nodes to compute Chebychev approximation of expected value funtion#
		x_prim_adj		<- 2*(x_prim[k,,] - rep(1,n.nodes)%*%t(cheby_init$lower))/#
							(rep(1,n.nodes) %*% t(cheby_init$upper - cheby_init$lower)) - 1#
		T 				<- apply(x_prim_adj,1,cheb_polynm_multD,cheby_init$Polynomial.degree)#
		ET				<- apply(T,1,function(x) x %*% GH_init$weights)/pi#
		Ew				<- ET %*% DP_list$Cheb.theta#
		v[k]			<- flow_u[k] + param_list$beta * Ew	#
	}
v
max_v 	<- max(v)#
	v		<- v - max_v#
	p 		<- exp(v)/sum(exp(v))
list(state=state,expected.next.state=c(EI[which.max(v)],state[2]),choice=which.max(v),probability = p)
state: a single D-dimentional state#
	n.nodes <- nrow(GH_init$nodes)#
	m		<- DP_list$consumption["m"]#
	n		<- DP_list$consumption["n"]#
	x_prim	<- array(NA,c(K,n.nodes,state_dim))#
	EI		<- rep(NA,K)#
	flow_u	<- rep(NA,K)#
	v		<- rep(NA,K)#
	for(k in 1:K){#
		sigma 	<- sigma_Q[k]#
		a0 		<- -(m/n + mu_Q[k])/sigma#
		b0 		<- -(m/(n-1) + mu_Q[k])/sigma#
		mu 		<- state[I.idx] + mu_Q[k]#
		if(pnorm(a0)<set_list$Phi.bound){#
			EQ_lower	<- 0 #
			EQ2_lower	<- 0#
		}else{#
			rho 		<- dnorm(a0)/pnorm(a0)#
			EQ_lower	<- mu - sigma*rho#
			EQ2_lower	<- mu^2 - 2*mu*sigma*rho + sigma^2*(1+a0*rho)#
		}#
#
		if(pnorm(-b0)<set_list$Phi.bound){#
			EQ_upper	<- 0#
			EQ2_upper	<- 0#
		}else{#
			rho 		<- dnorm(b0)/pnorm(-b0)#
			EQ_upper	<- mu + sigma*rho#
			EQ2_upper	<- mu^2 + 2*mu*sigma*rho +sigma^2*(1+b0*rho)#
		}#
#
		p.mid <- pnorm(b0) - pnorm(a0)#
		if(p.mid<set_list$Phi.bound){#
			EQ_mid		<- 0 #
			EQ2_mid		<- 0#
			Ec_mid		<- 0#
			Ec2_mid		<- 0#
			EI_mid		<- 0#
			EI2_mid		<- 0 #
		}else{#
			EQ_mid		<- mu - sigma*(dnorm(b0)-dnorm(a0))/p.mid#
			EQ2_mid		<- mu^2 - 2*mu*sigma*(dnorm(b0) - dnorm(a0))/p.mid + sigma^2*(1 - (b0*dnorm(b0) - a0*dnorm(a0))/p.mid)#
			Ec_mid		<- m*p.mid + n*EQ_mid#
			Ec2_mid		<- m^2*p.mid + 2*m*n*EQ_mid + n^2*EQ2_mid#
			EI_mid		<- -m*p.mid - (n-1)*EQ_mid#
			EI2_mid		<- m^2*p.mid + 2*m*(n-1)*EQ_mid + (n-1)^2*EQ2_mid#
		}#
#
		# Expected consumption, inventory and flow utility#
		Ec 			<- EQ_upper + Ec_mid#
		Ec2			<- EQ2_upper + Ec2_mid#
		EI_prim		<- EQ_lower + EI_mid#
		EI2_prim	<- EQ2_lower + EI2_mid#
		flow_u[k]	<- with(param_list, lambda1*Ec + lambda2*Ec2 - tau1*EI_prim - tau2*EI2_prim)#
		# The nodes at which to compute integral of value function#
		I_prim		<- cbind(-m-(n-1)*(mu + sqrt(2)*sigma*GH_init$nodes[,I.idx]), #
							 mu + sqrt(2)*sigma*GH_init$nodes[,I.idx]	)#
		I_prim		<- apply(I_prim,1,function(x) min(max(x[1],0),x[2]) )#
		y_prim		<- state[y.idx] + sqrt(2)*param_list$sigma_y * GH_init$nodes[,y.idx]#
		x_prim[k,,I.idx] <- sapply(I_prim, function(x) min(max(x,cheby_init$lower[I.idx]),cheby_init$upper[I.idx]) )#
		x_prim[k,,y.idx] <- sapply(y_prim, function(x) min(max(x,cheby_init$lower[y.idx]),cheby_init$upper[y.idx]) )#
		# Re-normalize nodes to compute Chebychev approximation of expected value funtion#
		x_prim_adj		<- 2*(x_prim[k,,] - rep(1,n.nodes)%*%t(cheby_init$lower))/#
							(rep(1,n.nodes) %*% t(cheby_init$upper - cheby_init$lower)) - 1#
		T 				<- apply(x_prim_adj,1,cheb_polynm_multD,cheby_init$Polynomial.degree)#
		ET				<- apply(T,1,function(x) x %*% GH_init$weights)/pi#
		Ew				<- ET %*% DP_list$Cheb.theta#
		v[k]			<- flow_u[k] + param_list$beta * Ew	#
		EI[k]			<- EI_prim#
	}#
	max_v 	<- max(v)#
	v		<- v - max_v#
	p 		<- exp(v)/sum(exp(v))
list(state=state,expected.next.state=c(EI[which.max(v)],state[2]),choice=which.max(v),probability = p)
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]
y
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')
Simulate a sequence of choice given an initial state#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
k_seq <- choice_sequence(5,y,DP_list)
str(k_seq)
k_seq$choic
k_seq$choice
str(DP_list)
library(scatterplot3d)
scatterplot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn)
?scatterplot3d
scatterplot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,type="b")
scatterplot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn)
library(rgl)
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn)
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function",type="s")
?plotwd
?ploted
?plot3d
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function",type="l")
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function",type="h")
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function",type="s")
library(rgl)#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .8,#
					sigma_y = 1)#
K <- 3#
mu_Q <- c(1, 1, 2)#
sigma_Q <- c(.03, .05, .1)					#
#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
omega_fn <- function(k,y){#
	if(y < 7 & k==K){#
		return(0)#
	}else{#
		if(y< 4 & k==K-1){#
			return(0)#
		}#
	}else{#
		return(2*y-.5*y^2)#
	}#
}
?else
omega_fn <- function(k,y){#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(2*y-.5*y^2)#
	}#
}
omega_fn(3,5)
omega_fn(3,10)
omega_fn <- function(k,y){#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(2*y-.1*y^2)#
	}#
}
omega_fn(3,10)
omega_fn(2,10)
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.1,-.1,-.1)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}
omega_fn(2,10)
omega_fn(3,10)
library(rgl)#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .8,#
					sigma_y = 1)#
K <- 3#
mu_Q <- c(1, 1, 2)#
sigma_Q <- c(.03, .05, .1)		#
#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.1,-.1,-.1)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)
Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Dynamic discrete choice model solution #
#
library(rgl)#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .8,#
					sigma_y = .5)#
K <- 3#
mu_Q <- c(1, 1, 2)#
sigma_Q <- c(.03, .05, .1)		#
#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.1,-.1,-.1)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.2,.25,.3)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}
Dynamic discrete choice model solution #
#
library(rgl)#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .8,#
					sigma_y = .5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.1,-.1,-.1)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.1,.15,.2)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)
Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)
Dynamic discrete choice model solution #
#
library(rgl)#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE)
library(rgl)#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .8,#
					sigma_y = .5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.1,-.1,-.1)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.1,.15,.2)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE)
DP_list <- policy_iteration(DP_init,verbose=TRUE)
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Dynamic discrete choice model solution #
#
library(rgl)#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .8,#
					sigma_y = .5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.1,-.1,-.1)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.1,.15,.2)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)
Dynamic discrete choice model solution #
#
library(rgl)#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')
data <- choice_sequence(5,y,DP_list)
str(data)
data$choice
mu_Q_fn(1,y.seq)
mu_Q_fn(1,y)
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.08,.12,.2)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)
str(data)
I0=5
y_seq=y
state[1,1] <- I0
t		<- length(y_seq)#
	state 	<- cbind(rep(NA,t),y_seq)#
	prob	<- matrix(NA,t,K)#
	choice	<- rep(NA,t)#
	cons	<- rep(NA,t)#
	state[1,1] <- I0
i <- 1
opt			<- choice_probability_once(state[i,],DP_list)		#
		prob[i,]	<- opt$probability#
		choice[i]	<- opt$choice
choice[i]
rnorm(1,mu=mu_Q_fn(choice[i],y_seq[i]),sd=sigma_Q[choice[i]])
u_Q_fn(choice[i],y_seq[i])
mu_Q_fn(choice[i],y_seq[i])
?rnorm
rnorm(1,mean=mu_Q_fn(choice[i],y_seq[i]),sd=sigma_Q[choice[i]])
opt$consumption
m
m		<- DP_list$consumption["m"]#
	n		<- DP_list$consumption["n"]
m
n
m		<- DP_list$consumption["m"]#
	n		<- DP_list$consumption["n"]#
	t		<- length(y_seq)#
	state 	<- cbind(rep(NA,t),y_seq)#
	prob	<- matrix(NA,t,K)#
	choice	<- rep(NA,t)#
	Ec		<- rep(NA,t)#
	Q		<- rep(NA,t)#
	cons	<- rep(NA,t)
state[1,1] <- I0
i <- 1
opt			<- choice_probability_once(state[i,],DP_list)		#
		prob[i,]	<- opt$probability#
		choice[i]	<- opt$choice#
		Ec[i]		<- opt$consumption
Q[i] 	<- rnorm(1,mean=mu_Q_fn(choice[i],y_seq[i]),sd=sigma_Q[choice[i]])#
			cons[i]	<- min(max(m+n*Q[i],0),state[i,I.idx] + Q[i])
Q[i]
cons[i]
m+n*Q[i]
Dynamic discrete choice model solution #
#
library(rgl)#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')
Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)
str(data)
data$choice
data$state
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')
data <- choice_sequence(5,y,DP_list)
str(data)
library(ggplot2)#
library(reshape2)
ggtmp <- data.frame(t=1:t,Inventory=data$state[,I.idx],Quantity=data$Q,Consumption=data$consumption)
head(ggtmp)
ggtmp <- melt(ggtmp,id="t")
head(ggtmp)
ggplot(ggtmp,aes(t,value)) + geom_point() + geom_line() + #
		facet_wrap(~variable)
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],Quantity=data$Q,Consumption=data$consumption)
head(ggtmp)
ggtmp <- melt(ggtmp,id=c("t","choice"))
head(ggtmp)
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable)
library(rgl)#
library(ggplot2)#
library(reshape2)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .8,#
					sigma_y = .5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.1,-.1,-.1)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.08,.2,.25)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,.5)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable)
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
str(data)
plot3d(x=data$state[,I.idx],y=data$state[,y.idx],data$probability[,1],xlab="I",ylab="y",zlab="Pr[1]")
plot3d(x=data$state[,I.idx],y=data$state[,y.idx],data$probability[,2],xlab="I",ylab="y",zlab="Pr[2]")
plot3d(x=data$state[,I.idx],y=data$state[,y.idx],data$probability[,3],xlab="I",ylab="y",zlab="Pr[3]")
Dynamic discrete choice model solution #
#
library(rgl)#
library(ggplot2)#
library(reshape2)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .8,#
					sigma_y = 1)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.1,-.1,-.1)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.08,.2,.25)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,.5)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
2000*40
1700*40
4000*.45
4000*.45-3980
Dynamic discrete choice model solution #
#
library(rgl)#
library(ggplot2)#
library(reshape2)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .8,#
					sigma_y = 1)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.1,-.1,-.1)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.08,.2,.25)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,.5)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)#
#
# Plot choice probability#
plot3d(x=data$state[,I.idx],y=data$state[,y.idx],data$probability[,1],xlab="I",ylab="y",zlab="Pr[1]")#
plot3d(x=data$state[,I.idx],y=data$state[,y.idx],data$probability[,2],xlab="I",ylab="y",zlab="Pr[2]")#
plot3d(x=data$state[,I.idx],y=data$state[,y.idx],data$probability[,3],xlab="I",ylab="y",zlab="Pr[3]")
Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .95,#
					sigma_y = 1)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.1,-.1,-.1)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.08,.2,.25)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,.5)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(10, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Dynamic discrete choice model solution #
#
library(rgl)#
library(ggplot2)#
library(reshape2)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -3,#
					beta 	= .95,#
					sigma_y = 1)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.2,-.1,-.2)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.1,.2,.3)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 10)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 20)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -2,#
					beta 	= .95,#
					sigma_y = 1)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.2,-.1,-.2)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.1,.2,.3)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 20)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")#
#
##################
# Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 8,#
					lambda2	= -1,#
					tau1 	= 3,#
					tau2 	= -2,#
					beta 	= .95,#
					sigma_y = 1)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.2,-.1,-.2)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.1,.2,.3)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 20)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
library(rgl)#
library(ggplot2)#
library(reshape2)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 9,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -2,#
					beta 	= .95,#
					sigma_y = 1.5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.2,-.1,-.2)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.1,.2,.3)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 20)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Dynamic discrete choice model solution #
#
library(rgl)#
library(ggplot2)#
library(reshape2)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 9,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -2,#
					beta 	= .95,#
					sigma_y = 1.5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.2,-.1,-.2)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.5,1,1.5)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 20)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 100#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Plot choice probability#
plot3d(x=data$state[,I.idx],y=data$state[,y.idx],data$probability[,1],xlab="I",ylab="y",zlab="Pr[1]")
str(data)
library(maxLik)
?maxLik
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Estimation_functions.R')
param.init <- c(lambda1	= 9,#
				lambda2	= -1,#
				tau1 	= 4,#
				tau2 	= -2,#
				beta 	= .95,#
				sigma_y = 1.5)#
sol <- maxLik(DP_likelihood,start=param.init)
sol <- maxLik(DP_likelihood,start=param.init,data=data)
print(param_list)
print(unlist(param_list))
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Estimation_functions.R')
param.init <- c(lambda1	= 9,#
				lambda2	= -1,#
				tau1 	= 4,#
				tau2 	= -2,#
				beta 	= .95,#
				sigma_y = 1.5)#
sol <- maxLik(DP_likelihood,start=param.init,data=data)
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Estimation_functions.R')
param.init <- c(lambda1	= 2,#
				lambda2	= -0.3,#
				tau1 	= 1,#
				tau2 	= -.5)#
sol <- maxLik(DP_likelihood,start=param.init,data=data)
tmp <- DP_likelihood(param.init,data=data)
str(tmp)
Simulate a single agent problem#
set.seed(6)#
t 	<- 200#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Estiamtion ##
###############
param.init <- c(lambda1	= 2,#
				lambda2	= -0.3,#
				tau1 	= 1,#
				tau2 	= -.5)#
tmp <- DP_likelihood(param.init,data=data)
str(tmp)
sol <- maxLik(DP_likelihood,start=param.init,data=data)
?maxLik
Dynamic discrete choice model solution #
#
library(rgl)#
library(ggplot2)#
library(reshape2)#
library(maxLik)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Estimation_functions.R')#
#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 9,#
					lambda2	= -1,#
					tau1 	= 4,#
					tau2 	= -2,#
					beta 	= .9,#
					sigma_y = 1.5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.2,-.1,-.2)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.5,1,1.5)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 20)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")#
#
##################
# Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 200#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Estiamtion ##
###############
param.init <- c(lambda1	= 2,#
				lambda2	= -0.3,#
				tau1 	= 1,#
				tau2 	= -.5)#
tmp <- DP_likelihood(param.init,data=data)#
sol <- maxLik(DP_likelihood,start=param.init,data=data)
sol <- maxLik(DP_likelihood,start=param.init,data=data,steptol=10e-4)
sol <- maxLik(DP_likelihood,start=param.init,data=data,method="BHHH")
str(sol)
sol
summary(sol)
Simulate a single agent problem#
set.seed(6)#
t 	<- 500#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Dynamic discrete choice model solution #
#
library(rgl)#
library(ggplot2)#
library(reshape2)#
library(maxLik)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Estimation_functions.R')#
#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 9,#
					lambda2	= -1,#
					tau1 	= 3,#
					tau2 	= -2,#
					beta 	= .9,#
					sigma_y = 1.5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.2,-.1,-.2)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.5,1,1.5)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 20)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 500#
y 	<- 7#
for(i in 2:t){#
	y <- c(y,rnorm(1,y[(i-1)],param_list$sigma_y))#
}#
y[y>state_upper[y.idx]] <- state_upper[y.idx]#
y[y<state_lower[y.idx]] <- state_lower[y.idx]#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
set.seed(6)#
t 	<- 500#
y 	<- 7#
for(i in 2:t){#
	y.draw <- rnorm(1,y[(i-1)],param_list$sigma_y)#
	y <- c(y,min(max(y.draw,state_lower[y.idx]),state_upper[y.idx]))#
}
plot(1:t,y)
Simulate a single agent problem#
set.seed(6)#
t 	<- 500#
y 	<- 7#
for(i in 2:t){#
	y.draw <- rnorm(1,y[(i-1)],param_list$sigma_y)#
	y <- c(y,min(max(y.draw,state_lower[y.idx]),state_upper[y.idx]))#
}#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Estiamtion ##
###############
param.init <- c(lambda1	= 2,#
				lambda2	= -0.3,#
				tau1 	= 1,#
				tau2 	= -.5)#
tmp <- DP_likelihood(param.init,data=data)#
sol <- maxLik(DP_likelihood,start=param.init,data=data,method="BHHH")
str(DP_list)
DP_list$Cheb.theta
param.init <- c(lambda1	= 2,#
				lambda2	= -0.3,#
				tau1 	= 1,#
				tau2 	= -.5)#
tmp <- DP_likelihood(param.init,data=data)
param.init1 <- c(lambda1	= 9,#
				lambda2	= -1,#
				tau1 	= 3,#
				tau2 	= -2)#
tmp1 <- DP_likelihood(param.init1,data=data)
identical(tmp,tmp1)
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Estimation_functions.R')
Simulate a single agent problem#
set.seed(6)#
t 	<- 200#
y 	<- 7#
for(i in 2:t){#
	y.draw <- rnorm(1,y[(i-1)],param_list$sigma_y)#
	y <- c(y,min(max(y.draw,state_lower[y.idx]),state_upper[y.idx]))#
}#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Estiamtion ##
###############
param.init <- c(lambda1	= 2,#
				lambda2	= -0.3,#
				tau1 	= 1,#
				tau2 	= -.5)#
tmp <- DP_likelihood(param.init,data=data)
param <- param.init
cur_param_list <- list(	lambda1	= param[1],#
							lambda2	= param[2],#
							tau1 	= param[3],#
							tau2 	= param[4],#
							beta 	= param_list$beta,#
							sigma_y = param_list$sigma_y)#
	if(cur_param_list$lambda1<0 | cur_param_list$lambda2>0){#
		return(NA)#
	}else{#
		print(unlist(cur_param_list))#
	}
DP_init <- Bellman_init(cur_param_list,K,GH_init,cheby_init,verbose=F) #
	DP_list <- policy_iteration(DP_init,verbose=F)
i <- 1
sol <- choice_probability_once(data$state[i,],DP_list)
str(data)
state <- data$state[i,]
n.nodes <- nrow(GH_init$nodes)#
	m		<- DP_list$consumption["m"]#
	n		<- DP_list$consumption["n"]#
	x_prim	<- array(NA,c(K,n.nodes,state_dim))#
	Ec_star	<- rep(NA,K)#
	EI		<- rep(NA,K)#
	flow_u	<- rep(NA,K)#
	v		<- rep(NA,K)
k <- 1
sigma 	<- sigma_Q[k]#
		a0 		<- -(m/n + mu_Q_fn(k,state[y.idx]))/sigma#
		b0 		<- -(m/(n-1) + mu_Q_fn(k,state[y.idx]))/sigma#
		mu 		<- state[I.idx] + mu_Q_fn(k,state[y.idx])
a
a0
m
str(DP_list)
if(!is.na(names(param))){#
		names(param) <- NULL#
	}#
	cur_param_list <- list(	lambda1	= param[1],#
							lambda2	= param[2],#
							tau1 	= param[3],#
							tau2 	= param[4],#
							beta 	= param_list$beta,#
							sigma_y = param_list$sigma_y)#
	if(cur_param_list$lambda1<0 | cur_param_list$lambda2>0){#
		return(NA)#
	}else{#
		print(unlist(cur_param_list))#
	}
Solve the dynamic solution for the given parameters#
	DP_init <- Bellman_init(cur_param_list,K,GH_init,cheby_init,verbose=F) #
	DP_list <- policy_iteration(DP_init,verbose=F)
str(DP_list)
Dynamic discrete choice model solution #
#
library(rgl)#
library(ggplot2)#
library(reshape2)#
library(maxLik)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Estimation_functions.R')#
#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 9,#
					lambda2	= -1,#
					tau1 	= 3,#
					tau2 	= -2,#
					beta 	= .9,#
					sigma_y = 1.5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.2,-.1,-.2)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.5,1,1.5)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 20)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 200#
y 	<- 7#
for(i in 2:t){#
	y.draw <- rnorm(1,y[(i-1)],param_list$sigma_y)#
	y <- c(y,min(max(y.draw,state_lower[y.idx]),state_upper[y.idx]))#
}#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
param.init <- c(lambda1	= 2,#
				lambda2	= -0.3,#
				tau1 	= 1,#
				tau2 	= -.5)#
tmp <- DP_likelihood(param.init,data=data)
str(tmp)
if(!any(is.na(names(param)))){#
		names(param) <- NULL#
	}
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Estimation_functions.R')
param.init <- c(lambda1	= 2,#
				lambda2	= -0.3,#
				tau1 	= 1,#
				tau2 	= -.5)#
tmp <- DP_likelihood(param.init,data=data)
sum(tmp)
sol <- maxLik(DP_likelihood,start=param.init,data=data,method="BHHH")
library(rgl)#
library(ggplot2)#
library(reshape2)#
library(maxLik)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Estimation_functions.R')#
#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 9,#
					lambda2	= -1,#
					tau1 	= 3,#
					tau2 	= -2,#
					beta 	= .9,#
					sigma_y = 1.5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.2,-.1,-.2)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.5,1,1.5)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 20)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)
str(DP_init)
str(DP_list)
Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")
Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 200#
y 	<- 7#
for(i in 2:t){#
	y.draw <- rnorm(1,y[(i-1)],param_list$sigma_y)#
	y <- c(y,min(max(y.draw,state_lower[y.idx]),state_upper[y.idx]))#
}#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
str(DP_list)
param.init <- c(lambda1	= 2,#
				lambda2	= -0.3,#
				tau1 	= 1,#
				tau2 	= -.5)#
tmp <- DP_likelihood(param.init,data=data)
str(DP_list)
param <- param.init
if(!any(is.na(names(param)))){#
		names(param) <- NULL#
	}
cur_param_list <- list(	lambda1	= param[1],#
							lambda2	= param[2],#
							tau1 	= param[3],#
							tau2 	= param[4],#
							beta 	= param_list$beta,#
							sigma_y = param_list$sigma_y)#
	if(cur_param_list$lambda1<0 | cur_param_list$lambda2>0){#
		return(NA)#
	}else{#
		print(unlist(cur_param_list))#
	}
Solve the dynamic solution for the given parameters#
	DP_init <- Bellman_init(cur_param_list,K,GH_init,cheby_init,verbose=F) #
	DP_list <- policy_iteration(DP_init,verbose=F)
str(DP_list)
p <- rep(NA,t)#
	for(i in 1:t){#
		sol <- choice_probability_once(data$state[i,],DP_list)#
		p[i]<- sol$probability[data$choice[i]]#
	}
str(p)
Dynamic discrete choice model solution #
#
library(rgl)#
library(ggplot2)#
library(reshape2)#
library(maxLik)#
#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Chebychev interpolation functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Gaussian_Hermite.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Policy_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Value_iteration_functions.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Model_simulation_function.R')#
source('~/Documents/Research/Store switching/Exercise/Shopping task DP/Simulation/Estimation_functions.R')#
#
### Set parameters ####
set_list <- list(	value.iter.max 	= 20,#
					policy.iter.max = 1000,#
					tol				= 10e-8,#
					display.freq	= 50,#
					Phi.bound		= 10e-8#
				)#
param_list <- list(	lambda1	= 9,#
					lambda2	= -1,#
					tau1 	= 3,#
					tau2 	= -2,#
					beta 	= .9,#
					sigma_y = 1.5)#
K <- 3#
#
# Set purchase utility function and transition function#
omega_fn <- function(k,y){#
	alpha1 <- c(1,2,3)#
	alpha2 <- c(-.2,-.1,-.2)#
	if(y < 7 & k==K){#
		return(0)#
	}else if(y< 4 & k==(K-1)){#
		return(0)#
	}else{#
		return(alpha1[k]*y-alpha2[k]*y^2)#
	}#
}			#
#
mu_Q_fn <- function(k,y){#
	alpha1 <- c(.5,1,1.5)#
	if(y < 7 & k==K){#
		return(0.1)#
	}else if(y< 4 & k==(K-1)){#
		return(0.1)#
	}else{#
		return(alpha1[k]*y)#
	}#
}#
sigma_Q <- c(.1,.5,1)#
# Initiate Gaussian-Hermite quadruture ##
state.name 	<- c('I','y')#
I.idx <- 1#
y.idx <- 2#
state_dim 	<- length(state.name)#
GH_num_nodes<- 5#
GH_init 	<- Gaussian_Hermite_init(GH_num_nodes,state_dim)#
#
# Initiate Chebychev approximation #
state_lower	<- c(0, 0)#
state_upper	<- c(20, 20)#
cheby_dgr	<- 3#
cheby_num_nodes <- 6#
cheby_init 	<- cheb_init(cheby_dgr,cheby_num_nodes,state_dim,state_lower,state_upper)#
#
# Initiate dynamic programming pre-computation #
DP_init <- Bellman_init(param_list,K,GH_init,cheby_init,verbose=TRUE) #
DP_list <- policy_iteration(DP_init,verbose=TRUE)#
#
# Plot value function#
plot3d(x=DP_list$state[,I.idx],y=DP_list$state[,y.idx],DP_list$value.fn,xlab="I",ylab="y",zlab="Value function")#
#
##################
# Simulate data # #
##################
# Simulate a single agent problem#
set.seed(6)#
t 	<- 200#
y 	<- 7#
for(i in 2:t){#
	y.draw <- rnorm(1,y[(i-1)],param_list$sigma_y)#
	y <- c(y,min(max(y.draw,state_lower[y.idx]),state_upper[y.idx]))#
}#
data <- choice_sequence(5,y,DP_list)#
#
# Plot path#
ggtmp <- data.frame(t=1:t,choice=data$choice,Inventory=data$state[,I.idx],y=y,Quantity=data$Q,Consumption=data$consumption)#
ggtmp <- melt(ggtmp,id=c("t","choice"))#
ggplot(ggtmp,aes(t,value)) + geom_point(aes(col=factor(choice))) + geom_line() + #
		facet_wrap(~variable,ncol=1)
Estiamtion ##
###############
param.init <- c(lambda1	= 2,#
				lambda2	= -0.3,#
				tau1 	= 1,#
				tau2 	= -.5)#
tmp <- DP_likelihood(param.init,data=data)#
sol <- maxLik(DP_likelihood,start=param.init,data=data,method="BHHH")
library(maxLik)
?maxLik
setwd("~/Documents/Research/Store switching/Exercise/Basket DP")#
source('Chebychev interpolation functions.R')#
source('Gaussian_Hermite.R')#
source('Policy_iteration_functions.R')
source('/Simulation/Value_iteration_functions.R')
source('Simulation/Value_iteration_functions.R')
setwd("~/Documents/Research/Store switching/Exercise/Basket DP")#
source('Chebychev interpolation functions.R')#
source('Gaussian_Hermite.R')#
source('Policy_iteration_functions.R')#
source('Simulation/Value_iteration_functions.R')#
source('Simulation/Model_simulation_function.R')#
source('Simulation/Estimation_functions.R')
